{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chameleon.pipeline.enhanced_rag_pipeline import EnhancedRAGPipeline\n",
    "from chameleon.base import PipelineConfig, RetrieverConfig, GeneratorConfig, MemoryConfig\n",
    "from chameleon.preprocessing.query_transformer import QueryTransformer\n",
    "from chameleon.postprocessing.contextual_compressor import ContextualCompressor\n",
    "from chameleon.memory.entity_memory import EntityMemory\n",
    "from chameleon.utils.logging_utils import setup_colored_logger, COLORS\n",
    "from setup import PipelineFactory\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading : Test Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:02:33 - \u001b[94mLoaded 208 document chunks from 15 source documents\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded 208 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Load African History dataset\n",
    "def load_sample_documents(max_docs: int = 20) -> List[Document]:\n",
    "    \"\"\"Load sample documents for demonstration.\"\"\"\n",
    "    documents = PipelineFactory.load_test_data_from_dataset(max_documents=max_docs)\n",
    "    print(f\"üìö Loaded {len(documents)} document chunks\")\n",
    "    return documents\n",
    "\n",
    "# Load documents\n",
    "documents = load_sample_documents(max_docs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_web_search_tool():\n",
    "    \"\"\"Create a simulated web search tool.\"\"\"\n",
    "    def search_web(query: str) -> str:\n",
    "        current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        return f\"üåê Web search results for '{query}' ({current_date}):\\n\" + \\\n",
    "               \"‚Ä¢ Recent developments in this area\\n\" + \\\n",
    "               \"‚Ä¢ Multiple authoritative sources found\\n\" + \\\n",
    "               \"‚Ä¢ Latest research indicates significant progress\"\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"web_search\",\n",
    "        description=\"Search for recent information not in documents\",\n",
    "        func=search_web\n",
    "    )\n",
    "\n",
    "def create_calculator_tool():\n",
    "    \"\"\"Create a simple calculator tool.\"\"\"\n",
    "    def calculate(expression: str) -> str:\n",
    "        try:\n",
    "            result = eval(expression)\n",
    "            return f\"üßÆ Calculation: {expression} = {result}\"\n",
    "        except:\n",
    "            return f\"‚ùå Invalid expression: {expression}\"\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"calculator\",\n",
    "        description=\"Perform mathematical calculations\",\n",
    "        func=calculate\n",
    "    )\n",
    "\n",
    "# Create tools\n",
    "tools = [create_web_search_tool(), create_calculator_tool()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:04:09 - \u001b[94mCreated buffer memory for pipeline\u001b[0m\n",
      "05:04:09 - \u001b[93mProcessing 208 documents in batches to avoid token limits\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating Basic RAG Pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:04:10 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:10 - Loading faiss.\n",
      "05:04:10 - Successfully loaded faiss.\n",
      "05:04:10 - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "05:04:10 - \u001b[94mProcessing batch 1/4 (50 documents)\u001b[0m\n",
      "05:04:11 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:11 - \u001b[94mProcessing batch 2/4 (50 documents)\u001b[0m\n",
      "05:04:12 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:12 - \u001b[94mProcessing batch 3/4 (50 documents)\u001b[0m\n",
      "05:04:13 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:13 - \u001b[94mProcessing batch 4/4 (8 documents)\u001b[0m\n",
      "05:04:14 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:14 - \u001b[92mCreated faiss vector store with text-embedding-3-small embeddings\u001b[0m\n",
      "05:04:14 - \u001b[94mCreated retriever with faiss vector store with text-embedding-3-small embeddings (collection: default_collection)\u001b[0m\n",
      "05:04:14 - \u001b[94mInitializing openai LLM generator with model gpt-4.1\u001b[0m\n",
      "05:04:14 - \u001b[94mConfiguring openai LLM with temperature=0.7, max_tokens=1000\u001b[0m\n",
      "05:04:14 - Split input into 1212 chunks\n",
      "05:04:17 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:04:18 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic RAG Pipeline created!\n"
     ]
    }
   ],
   "source": [
    "def create_basic_rag_pipeline(documents: List[Document]) -> Any:\n",
    "    \"\"\"Create a basic RAG pipeline.\"\"\"\n",
    "    print(\"üîß Creating Basic RAG Pipeline...\")\n",
    "    \n",
    "    pipeline = PipelineFactory.create_pipeline(\n",
    "        documents=documents,\n",
    "        title=\"Basic RAG Demo\",\n",
    "        rag_type=\"modular\",\n",
    "        memory_type=\"buffer\",\n",
    "        retriever_config={\n",
    "            \"top_k\": 3,\n",
    "            \"similarity_threshold\": 0.3\n",
    "        },\n",
    "        generator_config={\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"model_name\": \"gpt-4.1\",\n",
    "            \"provider\": \"openai\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Basic RAG Pipeline created!\")\n",
    "    return pipeline\n",
    "\n",
    "# Create basic pipeline\n",
    "basic_pipeline = create_basic_rag_pipeline(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating Enhanced RAG Pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:20:15 - Use pytorch device: mps\n",
      "05:20:15 - Use pytorch device_name: mps\n",
      "05:20:15 - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "/Users/svngoku/Documents/global_projects/Python/agents/CHAMELON-RAG/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bcfad0707e474ab28fd07a0494c2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced RAG Pipeline created!\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_rag_pipeline(documents: List[Document]) -> EnhancedRAGPipeline:\n",
    "    \"\"\"Create an enhanced RAG pipeline with advanced features.\"\"\"\n",
    "    print(\"üöÄ Creating Enhanced RAG Pipeline...\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = PipelineConfig(\n",
    "        rag_type=\"enhanced\",\n",
    "        retriever_config=RetrieverConfig(\n",
    "            top_k=5,\n",
    "            similarity_threshold=0.3,\n",
    "            retrieval_type=\"semantic\",\n",
    "            reranking_enabled=True,\n",
    "            filtering_enabled=True,\n",
    "            filtering_threshold=0.2,\n",
    "            multi_query_enabled=True,\n",
    "            embedding_model=\"all-MiniLM-L6-v2\",\n",
    "            parent_document_enabled=False\n",
    "        ),\n",
    "        generator_config=GeneratorConfig(\n",
    "            temperature=0.7,\n",
    "            max_tokens=1500,\n",
    "            model_name=\"gpt-4.1-mini\",\n",
    "            provider=\"openai\"\n",
    "        ),\n",
    "        memory_config=MemoryConfig(\n",
    "            memory_type=\"entity\",\n",
    "            max_history=10\n",
    "        ),\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    \n",
    "    # Create postprocessors\n",
    "    contextual_compressor = ContextualCompressor(\n",
    "        compression_mode=\"paragraph\",\n",
    "        min_relevance_score=0.7\n",
    "    )\n",
    "    \n",
    "    # Create enhanced pipeline\n",
    "    pipeline = EnhancedRAGPipeline(\n",
    "        title=\"Enhanced RAG Demo\",\n",
    "        documents=documents,\n",
    "        config=config,\n",
    "        preprocessors=[],\n",
    "        postprocessors=[contextual_compressor],\n",
    "        tools=tools,\n",
    "        enable_evaluation=False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Enhanced RAG Pipeline created!\")\n",
    "    return pipeline\n",
    "\n",
    "# Create enhanced pipeline\n",
    "enhanced_pipeline = create_enhanced_rag_pipeline(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(pipeline, queries: List[str], pipeline_name: str = \"Pipeline\"):\n",
    "    \"\"\"Test a pipeline with multiple queries.\"\"\"\n",
    "    print(f\"\\nüîç Testing {pipeline_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\nüìù Query {i}: {query}\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Use appropriate run method based on pipeline type\n",
    "            if hasattr(pipeline, 'run') and len(pipeline.run.__code__.co_varnames) == 2:\n",
    "                # Enhanced pipeline (only takes query)\n",
    "                response = pipeline.run(query)\n",
    "            else:\n",
    "                # Basic pipeline (takes query and documents)\n",
    "                response = pipeline.run(query)\n",
    "            \n",
    "            query_time = time.time() - start_time\n",
    "            total_time += query_time\n",
    "            \n",
    "            print(f\"‚ö° Time: {query_time:.2f}s\")\n",
    "            print(f\"ü§ñ Response: {response['response'][:300]}...\")\n",
    "            \n",
    "            if 'metadata' in response:\n",
    "                metadata = response['metadata']\n",
    "                if 'num_docs' in metadata:\n",
    "                    print(f\"üìä Documents used: {metadata['num_docs']}\")\n",
    "            \n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'response': response,\n",
    "                'time': query_time,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'error': str(e),\n",
    "                'time': 0,\n",
    "                'success': False\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful = [r for r in results if r['success']]\n",
    "    print(f\"\\nüìà {pipeline_name} Summary:\")\n",
    "    print(f\"  ‚Ä¢ Successful queries: {len(successful)}/{len(queries)}\")\n",
    "    if successful:\n",
    "        avg_time = total_time / len(successful)\n",
    "        print(f\"  ‚Ä¢ Average time: {avg_time:.2f}s\")\n",
    "        print(f\"  ‚Ä¢ Total time: {total_time:.2f}s\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries\n",
    "african_history_queries = [\n",
    "    \"What were the major kingdoms in ancient Africa?\",\n",
    "    \"How did iron production influence African societies?\",\n",
    "    \"What role did trade play in African empires?\",\n",
    "    \"Describe the Aksumite kingdom and its significance\",\n",
    "    \"What were the characteristics of Neolithic cultures in Africa?\"\n",
    "]\n",
    "\n",
    "rag_technical_queries = [\n",
    "    \"What are the advantages of modular RAG systems?\",\n",
    "    \"How does retrieval-augmented generation work?\",\n",
    "    \"What are the key components of a RAG pipeline?\",\n",
    "    \"Compare different RAG architectures\",\n",
    "    \"How do you optimize RAG performance?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:06 - Running modular RAG pipeline: Basic RAG Demo\n",
      "05:14:06 - Query: What were the major kingdoms in ancient Africa?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß BASIC RAG PIPELINE TEST\n",
      "\n",
      "üîç Testing Basic RAG\n",
      "============================================================\n",
      "\n",
      "üìù Query 1: What were the major kingdoms in ancient Africa?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:07 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:14:07 - \u001b[94mGenerating response for query: What were the major kingdoms in ancient Africa?...\u001b[0m\n",
      "05:14:07 - \u001b[94mUsing 3 documents for context\u001b[0m\n",
      "05:14:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:14:16 - \u001b[92mSuccessfully generated response\u001b[0m\n",
      "05:14:16 - Running modular RAG pipeline: Basic RAG Demo\n",
      "05:14:16 - Query: How did iron production influence African societies?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 9.71s\n",
      "ü§ñ Response: Ancient Africa was home to many influential kingdoms and states, each with its own unique history and contributions. Some of the major kingdoms in ancient Africa include:\n",
      "\n",
      "**1. Ancient Egypt (Dynastic Egypt)**\n",
      "- Location: Northeastern Africa, along the Nile River (modern Egypt)\n",
      "- Time period: c. 3,0...\n",
      "üìä Documents used: 3\n",
      "\n",
      "üìù Query 2: How did iron production influence African societies?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:16 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:14:16 - \u001b[94mGenerating response for query: How did iron production influence African societies?...\u001b[0m\n",
      "05:14:16 - \u001b[94mUsing 3 documents for context\u001b[0m\n",
      "05:14:27 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:14:27 - \u001b[92mSuccessfully generated response\u001b[0m\n",
      "05:14:27 - Running modular RAG pipeline: Basic RAG Demo\n",
      "05:14:27 - Query: What role did trade play in African empires?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 10.94s\n",
      "ü§ñ Response: Iron production had a profound and transformative impact on African societies. Here are some key ways it influenced social, economic, and political development:\n",
      "\n",
      "1. **Technological Advancement and Agriculture**\n",
      "   - The adoption of iron tools (such as hoes, axes, and ploughs) revolutionized agricult...\n",
      "üìä Documents used: 3\n",
      "\n",
      "üìù Query 3: What role did trade play in African empires?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:27 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "05:14:27 - \u001b[94mGenerating response for query: What role did trade play in African empires?...\u001b[0m\n",
      "05:14:27 - \u001b[94mUsing 3 documents for context\u001b[0m\n",
      "05:14:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:14:33 - \u001b[92mSuccessfully generated response\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 6.19s\n",
      "ü§ñ Response: Trade played a crucial role in the rise, prosperity, and influence of African empires. Here are some key ways in which trade impacted these societies:\n",
      "\n",
      "1. Economic Growth and Wealth: Trade brought significant wealth to African empires. By exchanging regional products‚Äîsuch as gold, ivory, camwood (us...\n",
      "üìä Documents used: 3\n",
      "\n",
      "üìà Basic RAG Summary:\n",
      "  ‚Ä¢ Successful queries: 3/3\n",
      "  ‚Ä¢ Average time: 8.95s\n",
      "  ‚Ä¢ Total time: 26.84s\n"
     ]
    }
   ],
   "source": [
    "# Test basic pipeline\n",
    "print(\"üîß BASIC RAG PIPELINE TEST\")\n",
    "basic_results = test_pipeline(basic_pipeline, african_history_queries[:3], \"Basic RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Enhanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:18 - Running enhanced RAG pipeline: Enhanced RAG Demo\n",
      "05:21:18 - Query: What were the major kingdoms in ancient Africa?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ ENHANCED RAG PIPELINE TEST\n",
      "\n",
      "üîç Testing Enhanced RAG\n",
      "============================================================\n",
      "\n",
      "üìù Query 1: What were the major kingdoms in ancient Africa?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:19 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59af984cbacc4589aa0dbca288cae237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ff421a06c240fc969ee7519d423085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70e60c66f8c4b188e94af563202e328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7371f134e7d84ae88e57369d223d7b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5440ff9494f4ed2be4102588f2a4bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdb78579a4b4e0e9ea741461ac14917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:27 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:30 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:36 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:39 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:41 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:42 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:44 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:45 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:46 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:48 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:48 - Running enhanced RAG pipeline: Enhanced RAG Demo\n",
      "05:21:48 - Query: How did iron production influence African societies?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 29.86s\n",
      "ü§ñ Response: two major kingdoms in ancient Africa were:\n",
      "\n",
      "1. **The Kingdom of Kerma (ancient Kush)**: Located in upper Nubia (northern Sudan), Kerma was a significant power during the mid-2nd millennium BC, influencing trade routes and interactions with Middle Kingdom Egypt. (Document 1)\n",
      "\n",
      "2. **The Kingdom of Mero...\n",
      "üìä Documents used: 2\n",
      "\n",
      "üìù Query 2: How did iron production influence African societies?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:48 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:49 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de93b18977246f7bc2347f0363d5fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1ce3141a154af483ff33b46f10423a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371ad4834b91442cb00a0b057ab928ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5a1214d9c2475db2dba3230bf51a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7665f2404f7549afba133b8c81a24a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d4135728d540199ff21529ab04f3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:21:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:00 - Running enhanced RAG pipeline: Enhanced RAG Demo\n",
      "05:22:00 - Query: What role did trade play in African empires?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 12.57s\n",
      "ü§ñ Response: The provided context does not contain information about how iron production influenced African societies. Therefore, I am unable to answer your question based on the given documents. If you have more specific information or documents related to iron production in African societies, please share them...\n",
      "üìä Documents used: 0\n",
      "\n",
      "üìù Query 3: What role did trade play in African empires?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af9db28ad504e3f94e3f75f14da75b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33dfd1440fe4be78d928d88cf620fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe524efd2044ba8a01a6b5ea9b567f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caaebeac73d4d63920166f0faa6d6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2eb0175bae413aab5c025b84ff7429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e51f4ef80fc4417ab83d5ee001f76d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:10 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:14 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:15 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:15 - Running enhanced RAG pipeline: Enhanced RAG Demo\n",
      "05:22:15 - Query: Describe the Aksumite kingdom and its significance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 15.06s\n",
      "ü§ñ Response: The provided context does not contain specific information about the role of trade in African empires. Therefore, I am unable to answer your question based on the given documents. If you have more detailed information or documents related to trade in African empires, please share them, and I will be...\n",
      "üìä Documents used: 0\n",
      "\n",
      "üìù Query 4: Describe the Aksumite kingdom and its significance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:17 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:17 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:18 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83128edc39444ebe8f8b21604c1176ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5006fdcfa204fddbe4336a1b5b6191b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbaf2383e854b8abab925d43fa0d87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d850fe08ceb480c95784720a907c12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b71e770415d4c61be03a7fee6b515c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4a8b81136243a59f7d25debed14475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:28 - Running enhanced RAG pipeline: Enhanced RAG Demo\n",
      "05:22:28 - Query: What were the characteristics of Neolithic cultures in Africa?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 12.89s\n",
      "ü§ñ Response: The provided context does not contain information about the Aksumite kingdom or its significance. Therefore, I am unable to answer your question based on the given documents. If you have more specific information or documents related to the Aksumite kingdom, please share them, and I will be happy to...\n",
      "üìä Documents used: 0\n",
      "\n",
      "üìù Query 5: What were the characteristics of Neolithic cultures in Africa?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:30 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:30 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61cb5e8d941447592cd1c178fe2d829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6e32b91c5444bcb9411b38fa18ca1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d01923f3364210a937fe999cf2adf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e23208599d4746a8c4b731256fe848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6906cecf20ca4327bb827d315d4b2fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20b57b94305472691e1e692685a076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:22:37 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:38 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:38 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:39 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:39 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:40 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:41 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:41 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:42 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:42 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:52 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "05:22:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Time: 27.65s\n",
      "ü§ñ Response: Neolithic cultures in Africa, beginning around 12,000 years ago, exhibited a wide range of developments that emerged independently across different regions. Key characteristics include:\n",
      "\n",
      "1. **Domestication and Agriculture**: Plants and animals were domesticated. In West Africa, pottery, livestock, a...\n",
      "üìä Documents used: 2\n",
      "\n",
      "üìà Enhanced RAG Summary:\n",
      "  ‚Ä¢ Successful queries: 5/5\n",
      "  ‚Ä¢ Average time: 19.60s\n",
      "  ‚Ä¢ Total time: 98.02s\n"
     ]
    }
   ],
   "source": [
    "# Test enhanced pipeline\n",
    "print(\"\\nüöÄ ENHANCED RAG PIPELINE TEST\")\n",
    "enhanced_results = test_pipeline(enhanced_pipeline, african_history_queries, \"Enhanced RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PERFORMANCE COMPARISON\n",
      "==================================================\n",
      "Basic RAG:\n",
      "  ‚Ä¢ Avg time: 8.95s\n",
      "  ‚Ä¢ Avg response length: 2270 chars\n",
      "  ‚Ä¢ Success rate: 3/3 (100.0%)\n",
      "\n",
      "Enhanced RAG:\n",
      "  ‚Ä¢ Avg time: 19.60s\n",
      "  ‚Ä¢ Avg response length: 829 chars\n",
      "  ‚Ä¢ Success rate: 5/5 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_performance(basic_results: List[Dict], enhanced_results: List[Dict]):\n",
    "    \"\"\"Analyze and compare pipeline performance.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Extract successful results\n",
    "    basic_success = [r for r in basic_results if r['success']]\n",
    "    enhanced_success = [r for r in enhanced_results if r['success']]\n",
    "    \n",
    "    if not basic_success or not enhanced_success:\n",
    "        print(\"‚ùå Insufficient data for comparison\")\n",
    "        return\n",
    "    \n",
    "    # Calculate metrics\n",
    "    basic_times = [r['time'] for r in basic_success]\n",
    "    enhanced_times = [r['time'] for r in enhanced_success]\n",
    "    \n",
    "    basic_lengths = [len(r['response']['response']) for r in basic_success]\n",
    "    enhanced_lengths = [len(r['response']['response']) for r in enhanced_success]\n",
    "    \n",
    "    # Display comparison\n",
    "    print(\"üìä PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Basic RAG:\")\n",
    "    print(f\"  ‚Ä¢ Avg time: {sum(basic_times)/len(basic_times):.2f}s\")\n",
    "    print(f\"  ‚Ä¢ Avg response length: {sum(basic_lengths)/len(basic_lengths):.0f} chars\")\n",
    "    print(f\"  ‚Ä¢ Success rate: {len(basic_success)}/{len(basic_results)} ({len(basic_success)/len(basic_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nEnhanced RAG:\")\n",
    "    print(f\"  ‚Ä¢ Avg time: {sum(enhanced_times)/len(enhanced_times):.2f}s\")\n",
    "    print(f\"  ‚Ä¢ Avg response length: {sum(enhanced_lengths)/len(enhanced_lengths):.0f} chars\")\n",
    "    print(f\"  ‚Ä¢ Success rate: {len(enhanced_success)}/{len(enhanced_results)} ({len(enhanced_success)/len(enhanced_results)*100:.1f}%)\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_performance(basic_results, enhanced_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
